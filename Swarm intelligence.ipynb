{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRpiwWNUEJqZtuPXdVqBVG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahsan-1114/LAB-AI/blob/main/Swarm%20intelligence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCs1uSL6cK-n",
        "outputId": "36f6f4af-1e24-44ce-cdc5-e96faaabafb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global Best Position:  [2.60000884 2.79979903]\n",
            "Best Fitness Value:  2.0233779243738273e-07\n",
            "Average Particle Best Fitness Value:  0.0009872491607702922\n",
            "Number of Generation:  66\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#Swarm Intelligence:\n",
        "\n",
        "##Coding and Visualising Particle Swarm Optimisation in Python Nature-inspired algorithm explained with simple code and animation Fish Swarm Photo by Sebastian Pena Lambarri on Unsplash In this article, we explore the theoretical aspects of the nature-inspired optimisation algorithm, Particle Swarm Optimisation, and then apply the algorithm to a simple example in Python, representing it in an animated gif so that we can see how it works.\n",
        "\n",
        "##If you are training a deep learning model with a stochastic gradient descent with backpropagation and cannot escape from the local minima, this article may help you to find an alternative approach to resolve the problem.\n",
        "\n",
        "##A swarm is a collection of agents or organisms; swarm intelligence can be defined as the social behaviours of a swarm in which autonomous individuals interact with each other in a decentralised and self-organised manner. The interaction of individuals improves the empirical knowledge about the environment and brings the swarm to the optimal state.\n",
        "\n",
        "##We can observe such intelligence in nature. For example, ants are known to find the shortest path from their colony to a food source. In the beginning, individuals explore various directions from and to the destination. When a favourable route is found, ants mark the path with pheromones which are chemical substances ants deposit on the ground. As more ants take the same trail, the pheromones intensify, attracting more ants. Consequently, the majority of ants follow and converge to the shortest path.\n",
        "\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import animation\n",
        "     \n",
        "##Define fitness function\n",
        "\n",
        "##We use the function: f(x,y)=(x-2y+3)^2+(2x+y-8)^2. The global minimum of this function is 0. All particles should move from random points towards the optimal position of x and y coordinates, where the value becomes near 0.\n",
        "\n",
        "\n",
        "# Fitness function\n",
        "# We assume the problem can be expressed by the following equation: \n",
        "# f(x1,x2)=(x1+2*-x2+3)^2 + (2*x1+x2-8)^2\n",
        "# The objective is to find a minimum which is 0\n",
        "\n",
        "def fitness_function(x1,x2):\n",
        "  f1=x1+2*-x2+3\n",
        "  f2=2*x1+x2-8\n",
        "  z = f1**2+f2**2\n",
        "  return z\n",
        "     \n",
        "#Update velocity\n",
        "\n",
        "#We apply the random values for r1,r2 and w. c1 and c2 are given smaller values at 0.1. The inertia value can be scheduled; starting from 0.9 and gradually reducing to 0.4. In our case, we generate the normal distribution with min 0.5 and max 1 and randomly select a value at each generation, following the experiments by [3].\n",
        "\n",
        "\n",
        "def update_velocity(particle, velocity, pbest, gbest, w_min=0.5, max=1.0, c=0.1):\n",
        "  # Initialise new velocity array\n",
        "  num_particle = len(particle)\n",
        "  new_velocity = np.array([0.0 for i in range(num_particle)])\n",
        "  # Randomly generate r1, r2 and inertia weight from normal distribution\n",
        "  r1 = random.uniform(0,max)\n",
        "  r2 = random.uniform(0,max)\n",
        "  w = random.uniform(w_min,max)\n",
        "  c1 = c\n",
        "  c2 = c\n",
        "  # Calculate new velocity\n",
        "  for i in range(num_particle):\n",
        "    new_velocity[i] = w*velocity[i] + c1*r1*(pbest[i]-particle[i])+c2*r2*(gbest[i]-particle[i])\n",
        "  return new_velocity\n",
        "     \n",
        "#Update position\n",
        "\n",
        "#As described in the algorithm, the new position is a sum of the current position and velocity.\n",
        "\n",
        "\n",
        "def update_position(particle, velocity):\n",
        "  # Move particles by adding velocity\n",
        "  new_particle = particle + velocity\n",
        "  return new_particle\n",
        "     \n",
        "#PSO's main function\n",
        "\n",
        "#Firstly, we initialise the particles, their best position, velocity and fitness value. We also set the global best position based on the particles’ initial position. Then we loop from one generation to another. The algorithm should stop when it reaches the max number of generations or a success criterion. In our case, it is when the average fitness value surpasses a specific value.\n",
        "\n",
        "\n",
        "def pso_2d(population, dimension, position_min, position_max, generation, fitness_criterion):\n",
        "  # Initialisation\n",
        "  # Population\n",
        "  particles = [[random.uniform(position_min, position_max) for j in range(dimension)] for i in range(population)]\n",
        "  # Particle's best position\n",
        "  pbest_position = particles\n",
        "  # Fitness\n",
        "  pbest_fitness = [fitness_function(p[0],p[1]) for p in particles]\n",
        "  # Index of the best particle\n",
        "  gbest_index = np.argmin(pbest_fitness)\n",
        "  # Global best particle position\n",
        "  gbest_position = pbest_position[gbest_index]\n",
        "  # Velocity (starting from 0 speed)\n",
        "  velocity = [[0.0 for j in range(dimension)] for i in range(population)]\n",
        "  \n",
        "  # Loop for the number of generation\n",
        "  for t in range(generation):\n",
        "    # Stop if the average fitness value reached a predefined success criterion\n",
        "    if np.average(pbest_fitness) <= fitness_criterion:\n",
        "      break\n",
        "    else:\n",
        "      for n in range(population):\n",
        "        # Update the velocity of each particle\n",
        "        velocity[n] = update_velocity(particles[n], velocity[n], pbest_position[n], gbest_position)\n",
        "        # Move the particles to new position\n",
        "        particles[n] = update_position(particles[n], velocity[n])\n",
        "    # Calculate the fitness value\n",
        "    pbest_fitness = [fitness_function(p[0],p[1]) for p in particles]\n",
        "    # Find the index of the best particle\n",
        "    gbest_index = np.argmin(pbest_fitness)\n",
        "    # Update the position of the best particle\n",
        "    gbest_position = pbest_position[gbest_index]\n",
        "\n",
        "  # Print the results\n",
        "  print('Global Best Position: ', gbest_position)\n",
        "  print('Best Fitness Value: ', min(pbest_fitness))\n",
        "  print('Average Particle Best Fitness Value: ', np.average(pbest_fitness))\n",
        "  print('Number of Generation: ', t)\n",
        "     \n",
        "#Set parameter values and run the algorithm\n",
        "\n",
        "\n",
        "population = 100\n",
        "dimension = 2\n",
        "position_min = -100.0\n",
        "position_max = 100.0\n",
        "generation = 400\n",
        "fitness_criterion = 10e-4\n",
        "     \n",
        "#We created 100 particles, of which positions were randomly placed at x and y coordinates, ranging between -100 and 100. As the function takes x and y, the particle’s position is 2-dimensional. The success criterion is 0.001 or lower. The programme should stop before the 400th generation if the criterion is met.\n",
        "\n",
        "#By running the algorithm with the above configurations, we obtained the following outcome:\n",
        "\n",
        "\n",
        "\n",
        "def pso_2dd(population, dimension, position_min, position_max, generation, fitness_criterion):\n",
        "  # Initialisation\n",
        "  # Population\n",
        "  particles = [[random.uniform(position_min, position_max) for j in range(dimension)] for i in range(population)]\n",
        "  # Particle's best position\n",
        "  pbest_position = particles\n",
        "  # Fitness\n",
        "  pbest_fitness = [fitness_function(p[0],p[1]) for p in particles]\n",
        "  # Index of the best particle\n",
        "  gbest_index = np.argmin(pbest_fitness)\n",
        "  # Global best particle position\n",
        "  gbest_position = pbest_position[gbest_index]\n",
        "  # Velocity (starting from 0 speed)\n",
        "  velocity = [[0.0 for j in range(dimension)] for i in range(population)]\n",
        "  \n",
        "  # Loop for the number of generation\n",
        "  for t in range(generation):\n",
        "    # Stop if the average fitness value reached a predefined success criterion\n",
        "    if np.average(pbest_fitness) <= fitness_criterion:\n",
        "      break\n",
        "    else:\n",
        "      for n in range(population):\n",
        "        # Update the velocity of each particle\n",
        "        velocity[n] = update_velocity(particles[n], velocity[n], pbest_position[n], gbest_position)\n",
        "        # Move the particles to new position\n",
        "        particles[n] = update_position(particles[n], velocity[n])\n",
        "    # Calculate the fitness value\n",
        "    pbest_fitness = [fitness_function(p[0],p[1]) for p in particles]\n",
        "    #print(\"pbest_fitness\")\n",
        "    # Find the index of the best particle\n",
        "    gbest_index = np.argmin(pbest_fitness)\n",
        "    # Update the position of the best particle\n",
        "    gbest_position = pbest_position[gbest_index]\n",
        "\n",
        "  # Print the results\n",
        "  print(\"Global Best Position: \", gbest_position)\n",
        "  print(\"Best Fitness Value: \", min(pbest_fitness))\n",
        "  print(\"Average Particle Best Fitness Value: \", np.average(pbest_fitness))\n",
        "  print(\"Number of Generation: \", t)\n",
        "     \n",
        "\n",
        "sol = pso_2dd(100, 2, -100.0, 100.0, 400, 10e-4)\n",
        "     \n"
      ]
    }
  ]
}